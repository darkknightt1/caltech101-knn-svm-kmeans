{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BO_j_7wdjPIZ"
   },
   "outputs": [],
   "source": [
    "#imported libs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.utils import get_file\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9145 files belonging to 101 classes.\n",
      "Using 7316 files for training.\n",
      "Found 9145 files belonging to 101 classes.\n",
      "Using 1829 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#dataset_dir  = r\"E:\\APPS\\PythonDataSets\\caltech\\caltech-101\\101_ObjectCategories\\101_ObjectCategories\"\n",
    "dataset_dir = r\"E:\\APPS\\PythonDataSets\\caltech\\caltech-101\\101_ObjectCategories\\filtered_preprocessed_categories\"\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "batch_size = 32\n",
    "image_size = (64, 128)\n",
    "\n",
    "# Load the training and validation datasets\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "def dataset_to_numpy(dataset):\n",
    "    \"\"\"\n",
    "    Convert a tf.data.Dataset into NumPy arrays for features and labels.\n",
    "    Args:\n",
    "        dataset: A tf.data.Dataset object.\n",
    "    Returns:\n",
    "        X: Numpy array of features (images).\n",
    "        y: Numpy array of labels.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for images, labels in dataset:\n",
    "        X.append(images.numpy())\n",
    "        y.append(labels.numpy())\n",
    "    return np.concatenate(X, axis=0), np.concatenate(y, axis=0)\n",
    "\n",
    "# Convert the train and validation datasets to NumPy arrays\n",
    "X_train, y_train = dataset_to_numpy(train_dataset)\n",
    "X_test, y_test = dataset_to_numpy(val_dataset)\n",
    "\n",
    "X_test =[cv2.resize(img.astype(np.uint8), (64, 128)) for img in X_test]\n",
    "X_train=[cv2.resize(img.astype(np.uint8), (64, 128)) for img in X_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM def\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def SVM(X_train, y_train,X_test,y_test):\n",
    "\n",
    "    # Step 4: Train LinearSVC with Grid Search for Hyperparameter Tuning\n",
    "    param_grid = {\n",
    "        'C': [0.1,10],  # Regularization parameter\n",
    "    }\n",
    "    svm = LinearSVC(max_iter=10000)  # Linear SVM for multiclass classification dual='auto',\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=3, verbose=2 , n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best Model\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "    # Step 5: Evaluate Model\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "\n",
    "    # Classification Report    \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))#,zero_division=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIVBeUWWjoEE"
   },
   "outputs": [],
   "source": [
    "#Color Histogram Extraction def\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    # Calculate the 3D histogram for the HSV channels\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, bins, [0, 256, 0, 256, 0, 256])\n",
    "    # Normalize the histogram to ensure invariance to lighting changes\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ic306d_1xb-h"
   },
   "outputs": [],
   "source": [
    "#HOG def\n",
    "def extract_hog_features(image):\n",
    "    # HOG parameters\n",
    "    winSize = (64, 128)\n",
    "    blockSize = (16, 16)\n",
    "    blockStride = (8, 8)\n",
    "    cellSize = (8, 8)\n",
    "    nbins = 9\n",
    "    \n",
    "    hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "    hog_features = hog.compute(image)\n",
    "     \n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "i70Yk1IzmN8f"
   },
   "outputs": [],
   "source": [
    "#LBP def\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "def extract_lbp_features(image, num_points=32, radius=8):\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    grid_size = (8, 8)  # Divide image into a 8x8 grid for histograms\n",
    "     # Compute LBP\n",
    "    lbp = local_binary_pattern(gray_img, num_points, radius, method=\"uniform\")\n",
    "    h, w = lbp.shape\n",
    "    \n",
    "    # Divide the image into grids and compute histograms\n",
    "    grid_h, grid_w = h // grid_size[0], w // grid_size[1]\n",
    "    histograms = []\n",
    "    \n",
    "    for i in range(grid_size[0]):\n",
    "        for j in range(grid_size[1]):\n",
    "            grid = lbp[i * grid_h:(i + 1) * grid_h, j * grid_w:(j + 1) * grid_w]\n",
    "            hist, _ = np.histogram(grid, bins=np.arange(0, num_points + 3), density=True)\n",
    "            histograms.append(hist)\n",
    "            \n",
    "    return np.concatenate(histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FyTP7LLSz97f"
   },
   "outputs": [],
   "source": [
    "# Step 1: Extract LBP features for train and test\n",
    "lbp_features_train = np.array([extract_lbp_features(image) for image in X_train])\n",
    "lbp_features_test  = np.array([extract_lbp_features(image) for image in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1fXjorG5-uP",
    "outputId": "c71caa0a-3376-411e-83b0-b6f23973de83"
   },
   "outputs": [],
   "source": [
    "# Step 2: Extract HOG features for train and test\n",
    "hog_features_train = np.array([extract_hog_features(image) for image in X_train])\n",
    "hog_features_test  = np.array([extract_hog_features(image) for image in X_test])\n",
    "scaler = StandardScaler()\n",
    "hog_features_train = scaler.fit_transform(hog_features_train)\n",
    "hog_features_test = scaler.transform(hog_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Extract Color Histogram features for train and test\n",
    "clhg_features_train = np.array([extract_color_histogram(image) for image in X_train])\n",
    "clhg_features_test  = np.array([extract_color_histogram(image) for image in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best Parameters: {'C': 1}\n",
      "Accuracy: 0.47785675232367414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.18      0.17        92\n",
      "           1       0.83      0.95      0.89       175\n",
      "           2       0.70      0.95      0.81        44\n",
      "           3       0.89      0.97      0.93       176\n",
      "           4       0.53      0.73      0.62        11\n",
      "           5       0.80      0.93      0.86       162\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.12      0.14      0.13         7\n",
      "          11       1.00      0.00      0.00         9\n",
      "          12       0.20      0.24      0.22        25\n",
      "          13       0.37      0.37      0.37        19\n",
      "          14       0.33      0.43      0.38         7\n",
      "          15       0.21      0.25      0.23        12\n",
      "          16       0.15      0.12      0.14        16\n",
      "          17       0.10      0.08      0.09        12\n",
      "          18       0.00      0.00      0.00        11\n",
      "          19       0.63      0.84      0.72        31\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       0.56      0.60      0.58        15\n",
      "          22       0.18      0.18      0.18        11\n",
      "          23       0.29      0.32      0.30        19\n",
      "          24       0.50      0.07      0.12        14\n",
      "          25       0.20      0.12      0.15        16\n",
      "          26       0.07      0.11      0.09         9\n",
      "          27       0.00      0.00      0.00        16\n",
      "          28       0.33      0.11      0.17         9\n",
      "          29       0.00      0.00      0.00        10\n",
      "          30       0.08      0.10      0.09        10\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.23      0.33      0.27         9\n",
      "          33       0.07      0.07      0.07        15\n",
      "          34       0.46      0.35      0.40        17\n",
      "          35       0.15      0.25      0.19         8\n",
      "          36       0.08      0.10      0.09        10\n",
      "          37       0.33      0.23      0.27        13\n",
      "          38       0.29      0.33      0.31        15\n",
      "          39       0.19      0.18      0.18        17\n",
      "          40       0.06      0.09      0.07        11\n",
      "          41       0.00      0.00      0.00        17\n",
      "          42       0.12      0.14      0.13         7\n",
      "          43       0.75      0.43      0.55         7\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00        11\n",
      "          46       0.67      0.60      0.63        20\n",
      "          47       0.06      0.07      0.06        14\n",
      "          48       0.40      0.33      0.36         6\n",
      "          49       0.10      0.12      0.11         8\n",
      "          50       0.14      0.12      0.13        17\n",
      "          51       0.24      0.26      0.25        19\n",
      "          52       0.60      0.50      0.55         6\n",
      "          53       0.20      0.27      0.23        11\n",
      "          54       0.19      0.20      0.19        15\n",
      "          55       0.33      0.42      0.37        24\n",
      "          56       0.29      0.25      0.27         8\n",
      "          57       0.54      0.41      0.47        17\n",
      "          58       0.17      0.18      0.17        17\n",
      "          59       0.00      0.00      0.00        10\n",
      "          60       0.18      0.18      0.18        11\n",
      "          61       0.25      0.10      0.14        10\n",
      "          62       0.00      0.00      0.00         5\n",
      "          63       0.36      0.29      0.32        17\n",
      "          64       0.33      0.33      0.33         3\n",
      "          65       0.71      0.91      0.80        11\n",
      "          66       0.00      0.00      0.00        11\n",
      "          67       0.25      0.25      0.25         4\n",
      "          68       0.20      0.20      0.20        10\n",
      "          69       0.73      0.73      0.73        11\n",
      "          70       0.40      0.22      0.29         9\n",
      "          71       0.29      0.22      0.25         9\n",
      "          72       0.25      0.38      0.30         8\n",
      "          73       1.00      0.00      0.00         7\n",
      "          74       0.42      0.33      0.37        15\n",
      "          75       0.50      0.50      0.50        14\n",
      "          76       0.08      0.09      0.09        11\n",
      "          77       0.50      0.14      0.22        14\n",
      "          78       0.43      0.50      0.46         6\n",
      "          79       0.27      0.31      0.29        13\n",
      "          80       0.33      0.09      0.14        11\n",
      "          81       0.14      0.11      0.12        19\n",
      "          82       0.00      0.00      0.00        17\n",
      "          83       0.50      0.18      0.27        11\n",
      "          84       0.31      0.31      0.31        13\n",
      "          85       0.14      0.20      0.17         5\n",
      "          86       0.00      0.00      0.00        10\n",
      "          87       0.50      0.31      0.38        16\n",
      "          88       0.56      0.45      0.50        11\n",
      "          89       0.50      0.17      0.25         6\n",
      "          90       0.25      0.40      0.31        10\n",
      "          91       0.50      0.33      0.40         9\n",
      "          92       0.56      0.77      0.65        13\n",
      "          93       0.35      0.44      0.39        16\n",
      "          94       0.49      0.69      0.57        52\n",
      "          95       0.20      0.12      0.15         8\n",
      "          96       0.27      0.50      0.35         8\n",
      "          97       0.00      0.00      0.00         7\n",
      "          98       0.54      0.58      0.56        12\n",
      "          99       0.71      0.36      0.48        14\n",
      "         100       0.67      0.89      0.76         9\n",
      "\n",
      "    accuracy                           0.48      1829\n",
      "   macro avg       0.30      0.27      0.27      1829\n",
      "weighted avg       0.45      0.48      0.45      1829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM(lbp_features_train,y_train,lbp_features_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mSVM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhog_features_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhog_features_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mSVM\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     14\u001b[0m svm \u001b[38;5;241m=\u001b[39m LinearSVC(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)  \u001b[38;5;66;03m# Linear SVM for multiclass classification dual='auto',\u001b[39;00m\n\u001b[0;32m     15\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(svm, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Best Model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m best_svm \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\Omar Wessam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omar Wessam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Omar Wessam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omar Wessam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Omar Wessam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omar Wessam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omar Wessam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Omar Wessam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SVM(hog_features_train,y_train,hog_features_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best Parameters: {'C': 10}\n",
      "Accuracy: 0.32640787315472936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.10      0.12        92\n",
      "           1       0.62      0.95      0.75       175\n",
      "           2       0.65      0.80      0.71        44\n",
      "           3       0.32      0.88      0.47       176\n",
      "           4       0.12      0.27      0.17        11\n",
      "           5       0.44      0.73      0.55       162\n",
      "           6       1.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       1.00      0.00      0.00        17\n",
      "          10       1.00      0.00      0.00         7\n",
      "          11       0.00      0.00      0.00         9\n",
      "          12       0.29      0.08      0.12        25\n",
      "          13       0.09      0.16      0.12        19\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       0.00      0.00      0.00        12\n",
      "          16       0.11      0.06      0.08        16\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        11\n",
      "          19       0.79      1.00      0.89        31\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       0.00      0.00      0.00        15\n",
      "          22       0.00      0.00      0.00        11\n",
      "          23       0.00      0.00      0.00        19\n",
      "          24       1.00      0.00      0.00        14\n",
      "          25       0.15      0.12      0.14        16\n",
      "          26       0.00      0.00      0.00         9\n",
      "          27       0.00      0.00      0.00        16\n",
      "          28       0.00      0.00      0.00         9\n",
      "          29       0.00      0.00      0.00        10\n",
      "          30       0.00      0.00      0.00        10\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.33      0.67      0.44         9\n",
      "          33       0.27      0.20      0.23        15\n",
      "          34       0.00      0.00      0.00        17\n",
      "          35       0.00      0.00      0.00         8\n",
      "          36       0.00      0.00      0.00        10\n",
      "          37       0.00      0.00      0.00        13\n",
      "          38       0.00      0.00      0.00        15\n",
      "          39       0.00      0.00      0.00        17\n",
      "          40       0.00      0.00      0.00        11\n",
      "          41       0.00      0.00      0.00        17\n",
      "          42       0.10      0.14      0.12         7\n",
      "          43       0.00      0.00      0.00         7\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00        11\n",
      "          46       0.00      0.00      0.00        20\n",
      "          47       0.11      0.14      0.12        14\n",
      "          48       0.00      0.00      0.00         6\n",
      "          49       0.17      0.12      0.14         8\n",
      "          50       0.10      0.06      0.07        17\n",
      "          51       0.14      0.05      0.08        19\n",
      "          52       0.50      0.17      0.25         6\n",
      "          53       0.08      0.09      0.09        11\n",
      "          54       0.00      0.00      0.00        15\n",
      "          55       0.22      0.25      0.24        24\n",
      "          56       0.00      0.00      0.00         8\n",
      "          57       0.00      0.00      0.00        17\n",
      "          58       0.00      0.00      0.00        17\n",
      "          59       0.00      0.00      0.00        10\n",
      "          60       0.30      0.27      0.29        11\n",
      "          61       0.00      0.00      0.00        10\n",
      "          62       0.00      0.00      0.00         5\n",
      "          63       0.00      0.00      0.00        17\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       0.07      0.18      0.10        11\n",
      "          66       0.00      0.00      0.00        11\n",
      "          67       0.00      0.00      0.00         4\n",
      "          68       1.00      0.00      0.00        10\n",
      "          69       0.20      0.36      0.26        11\n",
      "          70       0.00      0.00      0.00         9\n",
      "          71       1.00      0.00      0.00         9\n",
      "          72       0.25      0.75      0.38         8\n",
      "          73       0.00      0.00      0.00         7\n",
      "          74       0.00      0.00      0.00        15\n",
      "          75       0.00      0.00      0.00        14\n",
      "          76       0.00      0.00      0.00        11\n",
      "          77       0.00      0.00      0.00        14\n",
      "          78       0.00      0.00      0.00         6\n",
      "          79       0.10      0.08      0.09        13\n",
      "          80       0.00      0.00      0.00        11\n",
      "          81       0.31      0.21      0.25        19\n",
      "          82       0.00      0.00      0.00        17\n",
      "          83       0.30      0.27      0.29        11\n",
      "          84       0.00      0.00      0.00        13\n",
      "          85       0.25      0.20      0.22         5\n",
      "          86       0.00      0.00      0.00        10\n",
      "          87       0.00      0.00      0.00        16\n",
      "          88       0.24      0.36      0.29        11\n",
      "          89       0.29      0.33      0.31         6\n",
      "          90       0.33      0.70      0.45        10\n",
      "          91       0.25      0.22      0.24         9\n",
      "          92       0.12      0.31      0.17        13\n",
      "          93       0.00      0.00      0.00        16\n",
      "          94       0.14      0.08      0.10        52\n",
      "          95       0.00      0.00      0.00         8\n",
      "          96       0.00      0.00      0.00         8\n",
      "          97       0.00      0.00      0.00         7\n",
      "          98       0.00      0.00      0.00        12\n",
      "          99       0.00      0.00      0.00        14\n",
      "         100       0.22      0.22      0.22         9\n",
      "\n",
      "    accuracy                           0.33      1829\n",
      "   macro avg       0.15      0.11      0.09      1829\n",
      "weighted avg       0.25      0.33      0.25      1829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM(clhg_features_train,y_train,clhg_features_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
